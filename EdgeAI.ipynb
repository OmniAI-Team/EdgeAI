{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "import logging\n",
        "from telethon import TelegramClient, events, Button\n",
        "from openai import OpenAI\n",
        "\n",
        "# Enable nest_asyncio to avoid event loop conflicts in Jupyter or Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define necessary credentials\n",
        "api_id = \"21403141\"\n",
        "api_hash = \"74e9c96971cd422c1ba9878a13ea3db1\"\n",
        "bot_token = \"7847748804:AAGrnFtZLY9GH6K1Rk0Mo_fX5V0bLt0dcr4\"\n",
        "\n",
        "# Initialize the client\n",
        "client = TelegramClient('bot', api_id, api_hash)\n",
        "\n",
        "# Configure OpenRouter API\n",
        "openrouter_client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=\"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\"\n",
        ")\n",
        "\n",
        "# Define main function\n",
        "async def main():\n",
        "    await client.start(bot_token=bot_token)\n",
        "\n",
        "    # Handle /start command\n",
        "    @client.on(events.NewMessage(pattern='/start'))\n",
        "    async def start_handler(event):\n",
        "        user = await client.get_entity(event.sender_id)\n",
        "        first_name = user.first_name if user.first_name else \"there\"\n",
        "\n",
        "        await event.respond(\n",
        "            f\"👋 Hello {first_name}! I am EdgeAI from HyperVision. How can I assist you today? 🤖\",\n",
        "            buttons=[\n",
        "                [Button.url(\"🌐 Visit our website\", \"https://example.com\")],\n",
        "                [Button.url(\"ℹ️ Learn more about me\", \"https://example.com/info\")],\n",
        "                [Button.url(\"📢 Join our community\", \"https://t.me/your_channel\")]\n",
        "            ]\n",
        "        )\n",
        "        logging.info(f'Start command received from {event.sender_id}')\n",
        "\n",
        "    # Handle /info command\n",
        "    @client.on(events.NewMessage(pattern='/info'))\n",
        "    async def info_handler(event):\n",
        "        await event.respond(\"🤖 I am EdgeAI from HyperVision, developed by Wail Achouri. 🎯\")\n",
        "        logging.info(f'Info command received from {event.sender_id}')\n",
        "\n",
        "    # Handle /help command\n",
        "    @client.on(events.NewMessage(pattern='/help'))\n",
        "    async def help_handler(event):\n",
        "        help_text = (\n",
        "            \"🛠️ **Available Commands:**\\n\"\n",
        "            \"/start - Start the bot 🚀\\n\"\n",
        "            \"/help - Get help 📖\\n\"\n",
        "            \"/info - Learn more about me ℹ️\\n\"\n",
        "            \"/generate_image description - Generate an AI image 🎨\"\n",
        "        )\n",
        "        await event.respond(help_text)\n",
        "        logging.info(f\"Help command received from {event.sender_id}\")\n",
        "\n",
        "    # Handle AI-generated images\n",
        "    @client.on(events.NewMessage(pattern='/generate_image (.+)'))\n",
        "    async def image_handler(event):\n",
        "        user = await client.get_entity(event.sender_id)\n",
        "        first_name = user.first_name if user.first_name else \"Friend\"\n",
        "        prompt = event.pattern_match.group(1)\n",
        "\n",
        "        await event.respond(f\"🎨 Generating your image, {first_name}... Please wait. ⏳\")\n",
        "\n",
        "        try:\n",
        "            image_generation = await asyncio.to_thread(\n",
        "                openrouter_client.images.generate,\n",
        "                model=\"google/gemini-2.5-pro-exp-03-25:free\",\n",
        "                prompt=prompt,\n",
        "                n=1,\n",
        "                size=\"1024x1024\"\n",
        "            )\n",
        "\n",
        "            image_url = image_generation.data[0].url\n",
        "            await client.send_file(event.chat_id, image_url, caption=f\"✨ Here is your image, {first_name}! 🎨\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error generating image: {e}\")\n",
        "            await event.respond(\"⚠️ Sorry, I couldn't generate the image. Please try again later.\")\n",
        "\n",
        "    # Handle user messages\n",
        "    @client.on(events.NewMessage)\n",
        "    async def keyword_responder(event):\n",
        "        message = event.text.lower()\n",
        "        if message.startswith('/'):\n",
        "            return\n",
        "\n",
        "        user = await client.get_entity(event.sender_id)\n",
        "        first_name = user.first_name if user.first_name else \"Friend\"\n",
        "\n",
        "        try:\n",
        "            instructions = \"\"\"\n",
        "            You are EdgeAI, an advanced AI developed by HyperVision and created by Wail Achouri.\n",
        "            Your responses should be short, fast, and include relevant emojis.\n",
        "            Always personalize responses using the user's first name if available.\n",
        "            \"\"\"\n",
        "\n",
        "            completion = await asyncio.to_thread(\n",
        "                openrouter_client.chat.completions.create,\n",
        "                extra_headers={\n",
        "                    \"HTTP-Referer\": \"<YOUR_SITE_URL>\",\n",
        "                    \"X-Title\": \"<YOUR_SITE_NAME>\",\n",
        "                },\n",
        "                extra_body={},\n",
        "                model=\"google/gemini-2.5-pro-exp-03-25:free\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": instructions},\n",
        "                    {\"role\": \"user\", \"content\": f\"The user's name is {first_name} and they asked: {message}\"}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            response = completion.choices[0].message.content\n",
        "\n",
        "            await event.respond(response + \" 😊\")\n",
        "            logging.info(f\"Message received from {event.sender_id}: {event.text}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error while fetching response: {e}\")\n",
        "            await event.respond(\"⚠️ Sorry, I couldn't process your request right now.\")\n",
        "\n",
        "    await client.run_until_disconnected()\n",
        "\n",
        "# Run the main function\n",
        "await main()"
      ],
      "metadata": {
        "id": "hOf-RPG0o3WS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b113aab-341b-4401-af6c-471b1c7e48f2"
      },
      "id": "hOf-RPG0o3WS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error while fetching response: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n",
            "ERROR:root:Error generating image: Error code: 405\n",
            "ERROR:root:Error while fetching response: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n",
            "ERROR:root:Error while fetching response: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n",
            "ERROR:root:Error while fetching response: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install telethon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoHVMZiMjLxk",
        "outputId": "8732b7f9-ed33-4729-fd77-26d7b8101e26"
      },
      "id": "ZoHVMZiMjLxk",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting telethon\n",
            "  Downloading Telethon-1.39.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyaes (from telethon)\n",
            "  Downloading pyaes-1.6.1.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: rsa in /usr/local/lib/python3.11/dist-packages (from telethon) (4.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa->telethon) (0.6.1)\n",
            "Downloading Telethon-1.39.0-py3-none-any.whl (715 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.9/715.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyaes\n",
            "  Building wheel for pyaes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaes: filename=pyaes-1.6.1-py3-none-any.whl size=26346 sha256=64a7e76c35ce78910788b15c415181b8763232955721437b5ecea8a32d931e0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/52/33/010d0843550bffb6a591b11629070ae140c0ad4f53e68a3bd3\n",
            "Successfully built pyaes\n",
            "Installing collected packages: pyaes, telethon\n",
            "Successfully installed pyaes-1.6.1 telethon-1.39.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}